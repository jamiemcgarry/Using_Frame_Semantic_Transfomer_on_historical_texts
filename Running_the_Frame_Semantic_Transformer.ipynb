{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLcMSrtVhgbm",
        "outputId": "10cabe00-bc50-4343-9550-91db2eb8de4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting frame-semantic-transformer\n",
            "  Downloading frame_semantic_transformer-0.10.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting nlpaug<2.0.0,>=1.1.11 (from frame-semantic-transformer)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: nltk<4.0,>=3.7 in /usr/local/lib/python3.10/dist-packages (from frame-semantic-transformer) (3.8.1)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.20.1 in /usr/local/lib/python3.10/dist-packages (from frame-semantic-transformer) (3.20.3)\n",
            "Collecting pytorch-lightning<2.0.0,>=1.6.2 (from frame-semantic-transformer)\n",
            "  Downloading pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: sentencepiece<0.2.0,>=0.1.97 in /usr/local/lib/python3.10/dist-packages (from frame-semantic-transformer) (0.1.99)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from frame-semantic-transformer) (4.66.4)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from frame-semantic-transformer) (4.42.4)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (2.31.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (5.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0,>=3.7->frame-semantic-transformer) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0,>=3.7->frame-semantic-transformer) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0,>=3.7->frame-semantic-transformer) (2024.5.15)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (2.3.1+cu121)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (6.0.1)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (2024.6.1)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer)\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (4.12.2)\n",
            "Collecting lightning-utilities>=0.6.0.post0 (from pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer)\n",
            "  Downloading lightning_utilities-0.11.6-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.18.0->frame-semantic-transformer) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.18.0->frame-semantic-transformer) (0.23.5)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.18.0->frame-semantic-transformer) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.18.0->frame-semantic-transformer) (0.19.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (3.9.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (4.12.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.6.0.post0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (71.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (2024.7.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (2.1.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<2.0.0,>=1.1.11->frame-semantic-transformer) (1.7.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->pytorch-lightning<2.0.0,>=1.6.2->frame-semantic-transformer) (1.3.0)\n",
            "Downloading frame_semantic_transformer-0.10.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.6-py3-none-any.whl (26 kB)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, nlpaug, torchmetrics, pytorch-lightning, frame-semantic-transformer\n",
            "Successfully installed frame-semantic-transformer-0.10.0 lightning-utilities-0.11.6 nlpaug-1.1.11 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pytorch-lightning-1.9.5 torchmetrics-1.4.0.post0\n"
          ]
        }
      ],
      "source": [
        "!pip install frame-semantic-transformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKBbAORJhutf",
        "outputId": "7e730656-ddea-4a04-d0d5-a1cb73bd0fe7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybf_cnbmhxWZ",
        "outputId": "6ae892cc-802f-4aaa-d527-35831b2beb91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "metadata": {
        "id": "gvDjQFqth20o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4 html2text\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import html2text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOCj3CtKiFs8",
        "outputId": "e7f9c9b7-d085-4f2a-8fd5-770b964880f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Collecting html2text\n",
            "  Downloading html2text-2024.2.26.tar.gz (56 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Building wheels for collected packages: html2text\n",
            "  Building wheel for html2text (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33111 sha256=0edd40264b37a9d8d090df09423ebab28984405fecefa5d0162e08a70ac3a712\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/96/6d/a7eba8f80d31cbd188a2787b81514d82fc5ae6943c44777659\n",
            "Successfully built html2text\n",
            "Installing collected packages: html2text\n",
            "Successfully installed html2text-2024.2.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://gutenberg.org/cache/epub/15701/pg15701-images.html'\n",
        "extracted_html = requests.get(url)\n",
        "\n",
        "if extracted_html.status_code == 200:\n",
        "    extracted_content = extracted_html.text"
      ],
      "metadata": {
        "id": "HmZwmPYIiR1Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(extracted_content, 'html.parser')\n",
        "elems = soup.find_all([\"h2\", \"p\"])\n",
        "\n",
        "raw_sections = [\"\"]\n",
        "for e in elems:\n",
        "\n",
        "    if e.name == \"p\":\n",
        "\n",
        "        sub_elems = list(e.children)\n",
        "\n",
        "        for s in sub_elems:\n",
        "\n",
        "            if s.name is None:\n",
        "                raw_sections[-1] += s\n",
        "\n",
        "    else:\n",
        "        raw_sections.append(\"\")\n",
        "\n",
        "output_sections = []\n",
        "for r in raw_sections:\n",
        "\n",
        "    if len(r) > 500:\n",
        "        print(r[:500])\n",
        "        print(\"_____________________\")\n",
        "\n",
        "        output_sections.append(r)\n",
        "\n",
        "# 'output_sections' for final texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71tRG-0VjKn5",
        "outputId": "8a68eb47-b4a1-462a-e8be-d35f7eb845c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My dear Lord,—The paper which I take the\r\n",
            "liberty of sending to your Grace was, for the\r\n",
            "greater part, written during the last session. A few\r\n",
            "days after the prorogation some few observations were\r\n",
            "added. I was, however, resolved to let it lie by me\r\n",
            "for a considerable time, that, on viewing the matter\r\n",
            "at a proper distance, and when the sharpness of recent\r\n",
            "impressions had been worn off, I might be better\r\n",
            "able to form a just estimate of the value of my\r\n",
            "first opinions.I have just now read it o\n",
            "_____________________\n",
            "Approaching towards the close of a long period\r\n",
            "of public service, it is natural I should be\r\n",
            "desirous to stand well (I hope I do stand tolerably\r\n",
            "well) with that public which, with whatever fortune,\r\n",
            "I have endeavored faithfully and zealously to serve.I am also not a little anxious for some place in the\r\n",
            "estimation of the two persons to whom I address this\r\n",
            "paper. I have always acted with them, and with\r\n",
            "those whom they represent. To my knowledge, I\r\n",
            "have not deviated, no, not in the minutest p\n",
            "_____________________\n",
            "The French Revolution has been the subject of\r\n",
            "various speculations and various histories. As\r\n",
            "might be expected, the royalists and the republicans\r\n",
            "have differed a good deal in their accounts of the\r\n",
            "principles of that Revolution, of the springs which\r\n",
            "have set it in motion, and of the true character of\r\n",
            "those who have been, or still are, the principal actors\r\n",
            "on that astonishing scene.They who are inclined to think favorably of that\r\n",
            "event will undoubtedly object to every state of facts\r\n",
            "which\n",
            "_____________________\n",
            "[The Address of M. Brissot to his Constituents being now almost\r\n",
            "forgotten, it has been thought right to add, as an Appendix, that part\r\n",
            "of it to which Mr. Burke points our particular attention and upon\r\n",
            "which he so forcibly comments in his Preface.]Three sorts of anarchy have ruined our affairs\r\n",
            "in Belgium.The anarchy of the administration of Pache, which\r\n",
            "has completely disorganized the supply of our armies;\r\n",
            "which by that disorganization reduced the army of\r\n",
            "Dumouriez to stop in the middle of\n",
            "_____________________\n",
            "BEACONSFIELD, May 28,1795.My dear sir,—I have been told of the voluntary\r\n",
            "which, for the entertainment of the\r\n",
            "House of Lords, has been lately played by his Grace\r\n",
            "the **** of *******, a great deal at my expense, and\r\n",
            "a little at his own. I confess I should have liked the\r\n",
            "composition rather better, if it had been quite new.\r\n",
            "But every man has his taste, and his Grace is an admirer\r\n",
            "of ancient music.There may be sometimes too much even of a good\r\n",
            "thing. A toast is good, and a bumper is not bad:\r\n",
            "_____________________\n",
            "Of all things, an indiscreet tampering with the\r\n",
            "trade of provisions is the most dangerous, and\r\n",
            "it is always worst in the time when men are most\r\n",
            "disposed to it,—that is, in the time of scarcity; because\r\n",
            "there is nothing on which the passions of men\r\n",
            "are so violent, and their judgment so weak, and on\r\n",
            "which there exists such a multitude of ill-founded\r\n",
            "popular prejudices.The great use of government is as a restraint; and\r\n",
            "there is no restraint which it ought to put upon others,\r\n",
            "and upon itsel\n",
            "_____________________\n",
            "My lord,—I could hardly flatter myself with\r\n",
            "the hope that so very early in the season I\r\n",
            "should have to acknowledge obligations to the Duke\r\n",
            "of Bedford and to the Earl of Lauderdale. These\r\n",
            "noble persons have lost no time in conferring upon\r\n",
            "me that sort of honor which it is alone within their\r\n",
            "competence, and which it is certainly most congenial\r\n",
            "to their nature and their manners, to bestow.To be ill spoken of, in whatever language they\r\n",
            "speak, by the zealots of the new sect in philosophy\r\n",
            "and\n",
            "_____________________\n",
            "My Dear Sir,—Our last conversation, though\r\n",
            "not in the tone of absolute despondency, was\r\n",
            "far from cheerful. We could not easily account for\r\n",
            "some unpleasant appearances. They were represented\r\n",
            "to us as indicating the state of the popular mind;\r\n",
            "and they were not at all what we should have expected\r\n",
            "from our old ideas even of the faults and vices of\r\n",
            "the English character. The disastrous events which\r\n",
            "have followed one upon another in a long, unbroken,\r\n",
            "funereal train, moving in a procession tha\n",
            "_____________________\n",
            "My dear Sir,—I closed my first letter with\r\n",
            "serious matter, and I hope it has employed\r\n",
            "your thoughts. The system of peace must have a\r\n",
            "reference to the system of the war. On that ground,\r\n",
            "I must therefore again recall your mind to our original\r\n",
            "opinions, which time and events have not taught\r\n",
            "me to vary.My ideas and my principles led me, in this contest,\r\n",
            "to encounter France, not as a state, but as a faction.\r\n",
            "The vast territorial extent of that country, its immense\r\n",
            "population, its riches of p\n",
            "_____________________\n",
            "Dear Sir,—I thank you for the bundle of state-papers\r\n",
            "which I received yesterday. I have travelled\r\n",
            "through the negotiation,—and a sad, founderous\r\n",
            "road it is. There is a sort of standing jest against\r\n",
            "my countrymen,—that one of them on his journey\r\n",
            "having found a piece of pleasant road, he proposed\r\n",
            "to his companion to go over it again. This proposal,\r\n",
            "with regard to the worthy traveller's final destination,\r\n",
            "was certainly a blunder. It was no blunder\r\n",
            "as to his immediate satisfaction; for the \n",
            "_____________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this last two cells of code, after installing and importing all the necessary libraries, I import the specific text through 'requests' an 'beautiful soup'. The for loop in the cell above simply looks across all the content extracted from the project guttenberg webpage and finds instances of text 'p', which are indexed as actual text and not appendices, footnotes, and copyright information. This is indicated when 's' eqauls NONE. Therefore this code gives back only the actual written text of the auhtor.   "
      ],
      "metadata": {
        "id": "nHWgfa0mjVR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cut_text_B_8= output_sections[:2]\n",
        "#cut_text_B_8"
      ],
      "metadata": {
        "id": "Iv_7u8DKmzkZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "output_sections is numbered by sections of the text. Because the entirety of output_sections comprises of multiple letters of and phamplets of Edmund Burke's life, I wanted to break it up into each text so that I could label them and know later down the line which sentence belongs to which text. In this case 'B_8_cut_text' stands for a particular letter of Burkes. The next letter is B_9_cut_text and so on. However this step isn't neccessary and one could just join output sections into one string and work from there."
      ],
      "metadata": {
        "id": "RWh-aMOVnLbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B_8_raws = \"\\n\".join(cut_text_B_8)\n",
        "B_8_raw= B_8_raws.lower()\n",
        "#B_8_raw"
      ],
      "metadata": {
        "id": "obXj2m5-oHMp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "B_8_raws = B_8_raw.replace(\"\\\\\", \"\")\n",
        "\n",
        "B_8_raw = B_8_raw.replace(\"\\n\", \" \")\n",
        "B_8_raw = B_8_raw.replace(\"\\r\", \" \")\n",
        "B_8_raw = B_8_raw.replace(\"_\", \"\")\n",
        "B_8_raw = B_8_raw.replace(\"  \", \" \")\n",
        "#B_8_raw"
      ],
      "metadata": {
        "id": "SDjIBnuSo90H"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "these two cells joins the text into one string and then '.replaces' and unwanted characters with empty spaces"
      ],
      "metadata": {
        "id": "zuZHFfEopFxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(B_8_raw)\n",
        "\n",
        "sentences_B_8 = []\n",
        "\n",
        "for sent in doc.sents:\n",
        "  sentences_B_8.append(sent.text)\n",
        "\n",
        "#sentences_B_8"
      ],
      "metadata": {
        "id": "91yRjyaupvAc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentences_B_8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBq4CJm1qRwY",
        "outputId": "bb047fe9-5f47-4b92-8ca5-3d65b3aa0b03"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "475"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I then run the 'en_core_web_sum_lg' large language model from Spacy to split the text per sentence which gives a accurate list of sentences, from the text. As we can see this list of sentences (sentences_B_8) has 475 sentences within it."
      ],
      "metadata": {
        "id": "eE7H2s1jqWce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93Kf5sEirPMM",
        "outputId": "68482cd8-2232-4946-b44e-c131469d3a0d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_targets = ['despotism', 'democracy', 'republican', 'republics', 'government', 'monarchy', 'burthens', 'magistracy', 'monarchies', 'despotic', 'political', 'politics', 'politic', 'state', 'tyranny', 'oppression', 'oppressed', 'hereditary', 'nation', 'anarchy', 'liberty', 'freedom', 'revolution', 'patriots', 'patriotism', 'equality', 'rights', 'domination', 'slavery', 'licentiousness', 'aristocracy', 'executive', 'legislative', 'civil', 'laws', 'constitution', 'polity', 'discontents', 'subversion']\n",
        "target_lemmas = [lemmatizer.lemmatize(word) for word in base_targets]\n",
        "\n",
        "\n",
        "target_sentences_B_8 = []\n",
        "for sent in sentences_B_8:\n",
        "  tokenized = word_tokenize(sent)\n",
        "  lemmas = [lemmatizer.lemmatize(word) for word in tokenized]\n",
        "  if any(lemma in target_lemmas for lemma in lemmas):\n",
        "      target_sentences_B_8.append(sent)\n",
        "  else:\n",
        "    continue\n",
        "#target_sentences_B_8\n",
        "len(target_sentences_B_8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gh1H4FNqrn5M",
        "outputId": "863d695d-6c1d-4ceb-c983-9510be14b728"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this cell I filter out sentences by checking to see if each sentence has any words found in target_lemmas. Only sentences that do are appened to 'target_sentences_B_8'. As we can see this now gives us a list of 115 sentences which cut about three quartes of the original text."
      ],
      "metadata": {
        "id": "FerBrRYNrw2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from frame_semantic_transformer import FrameSemanticTransformer\n",
        "frame_transformer = FrameSemanticTransformer()"
      ],
      "metadata": {
        "id": "oCH7fjxasupT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_B_8 = frame_transformer.detect_frames_bulk(target_sentences_B_8)\n",
        "\n",
        "for i in result_B_8:\n",
        "  print(f\"Results found in: {i.sentence}\")\n",
        "  for frame in i.frames:\n",
        "    print(f\"FRAME: {frame.name}\")\n",
        "    for element in frame.frame_elements:\n",
        "        print(f\"{element.name}: {element.text}\")"
      ],
      "metadata": {
        "id": "cDTenir2s2AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell now runs inputs each sentence into the frame semantic transformer and holds the data in result_B_8. WARNING, only run this cell if you actually want to get the results. It can take a long time to complete and is very computationally intensive. In this case it won't take too long maybe 10 minutes."
      ],
      "metadata": {
        "id": "Rz58fbGEs9Lz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you do decide to run it make sure to save the results as a pickle file so that you don't have to run it again."
      ],
      "metadata": {
        "id": "h-zNAVBXtuMS"
      }
    }
  ]
}